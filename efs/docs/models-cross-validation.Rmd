---
title: "Models Cross Validation"
author: "Sanatan Das"
date: "May 24, 2018"
output:
  pdf_document:
    toc: yes
  html_document:
    number_sections: yes
    toc: yes
header-includes:
- \usepackage{titling}
- \pretitle{\begin{center}\LARGE\includegraphics[width=5cm]{logo.png}\\[\bigskipamount]}
- \posttitle{\end{center}}
urlcolor: blue
---

<script>
   $(document).ready(function() {
     $head = $('#header');
     $head.prepend('<img src=\"logo.png\" style=\"float: right;width: 150px;\"/>')
   });
</script>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_packages, warning=FALSE, message=FALSE, echo=FALSE}
library(tidyverse)
library(readxl)
library(broom)
library(knitr)
library(earth)
```

\newpage

# Initial Data Preparation

## Load the Data

```{r var1, eval=TRUE, echo=TRUE}

# load the data set from excel file
default_rates <- read_excel("C:/view/opt/apps/git/compscix-415-1-assignments/data/peps3xx.xls")

# add factor to the 'char' columns
default_rates$Name <- as.factor(default_rates$Name)
default_rates$State <- as.factor(default_rates$State)
default_rates$ZipCode <- as.factor(default_rates$ZipCode)
default_rates$ProgLength <- as.factor(default_rates$ProgLength)
default_rates$SchoolType <- as.factor(default_rates$SchoolType)
default_rates$EthnicCode <- as.factor(default_rates$EthnicCode)
default_rates$Prate <- as.factor(default_rates$Prate)
default_rates$CongDis <- as.factor(default_rates$CongDis)
# convert the columns to 'double' data type
default_rates$Drate <- as.double(default_rates$Drate)
default_rates$Num <- as.double(default_rates$Num)
default_rates$Denom <- as.double(default_rates$Denom)

```

## Split the Data (training set and test set)

```{r var2, eval=TRUE, echo=TRUE}

# split the data (training data - 80% and test data - 20%)
set.seed(29283)
# Let's create our training set using sample_frac.
train_set <- default_rates %>% sample_frac(0.8)
# Print train set
train_set
# let's create our testing set using the RecordId column. Fill in the blanks.
test_set <- default_rates %>% filter(!(default_rates$RecordId %in% train_set$RecordId))
# Print test set
test_set

```

```{r var3, eval=TRUE, echo=FALSE}

# Linear Regression model
lm_0 <- lm(Drate ~ ProgLength + SchoolType + Num + Denom + EthnicCode, data = default_rates)

# MARS model
mars_0 <- earth(Drate ~ ProgLength + SchoolType + Num + Denom + EthnicCode, data = default_rates, pmethod="backward", nprune=20, nfold=10);

# Function that returns Root Mean Squared Error
rmse <- function(error) {
    sqrt(mean(error^2))
}
 
# Function that returns Mean Absolute Error
mae <- function(error) {
    mean(abs(error))
}

```

# Evaluation of Linear Regression model

## Predict the test data (lm)

```{r var4, eval=TRUE, echo=TRUE}

lm_predict <- predict(lm_0, test_set)

```
## Predicted vs Actual

```{r var5, eval=TRUE, echo=TRUE}

plot(lm_predict,test_set$Drate, col=c('red', 'blue'), xlab="predicted", ylab="actual")

```

## Mean Absolute Error

```{r var6, eval=TRUE, echo=TRUE}

lm_diffs <- lm_predict - test_set$Drate
lm_mae <- mae(lm_diffs)
lm_mae

```

## Root Mean Squared Error

```{r var7, eval=TRUE, echo=TRUE}

lm_rmse <- rmse(lm_diffs)
lm_rmse

```

# Evaluation of MARS model 

## Predict the test data (mars)

```{r var8, eval=TRUE, echo=TRUE}

mars_predict <- predict(mars_0, test_set)[, 1]

```

## Predicted vs Actual

```{r var9, eval=TRUE, echo=TRUE}

plot(mars_predict,test_set$Drate, col=c('red', 'blue'), xlab="predicted", ylab="actual")

```

## Mean Absolute Error

```{r var10, eval=TRUE, echo=TRUE}

mars_diffs <- mars_predict - test_set$Drate
mars_mae <- mae(mars_diffs)
mars_mae

```

## Root Mean Squared Error

```{r var11, eval=TRUE, echo=TRUE}

mars_rmse <- rmse(mars_diffs)
mars_rmse

```

# Final Note

## Model Selection
From the above validation, we see that the Linear regression model has MAE = 3.88506 and RMSE = 5.346097 where the MARS model has MAE = 2.119824 and RMSE = 3.068444. So, the MARS model performs better on the test data. We will use the MARS model on our final application.


